### 一、电影评论：二分类问题

用密集连接的神经网络将向量输入划分为两个互斥的类别

#### 1、实验小结

1. 通常需要对原始数据进行大量预处理，以便将其转换为张量输入到神经网络中。单词序列可以编码为二进制向量，但也有其他编码方式。
2. 带有 relu 激活的 Dense 层堆叠，可以解决很多种问题（包括情感分类）
3. 对于二分类问题（两个输出类别），网络的最后一层应该是只有一个单元并使用 sigmoid激活的 Dense 层，网络输出应该是 0~1 范围内的标量，表示概率值。
4. 对于二分类问题的 sigmoid 标量输出，你应该使用 binary_crossentropy 损失函数。
5. 无论你的问题是什么，rmsprop 优化器通常都是足够好的选择。
6. 随着神经网络在训练数据上的表现越来越好，模型最终会过拟合，并在前所未见的数据上得到越来越差的结果。一定要一直监控模型在训练集之外的数据上的性能。

#### 2、改进

通过以下实验，你可以确信前面选择的网络架构是非常合理的，虽然仍有改进的空间。

1. 前面使用了两个隐藏层。你可以尝试使用一个或三个隐藏层，然后观察对验证精度和测
2. 试精度的影响。
3. 尝试使用更多或更少的隐藏单元，比如 32 个、64 个等。
4. 尝试使用 mse 损失函数代替 binary_crossentropy。 
5. 尝试使用 tanh 激活（这种激活在神经网络早期非常流行）代替 relu。

### 二、新闻分类：多分类问题

IMDB 和 MNIST 类似，路透社数据集也内置为 Keras 的一部分

#### 1、进一步的实验

1. 尝试使用更多或更少的隐藏单元，比如 32 个、128 个等。
2. 前面使用了两个隐藏层，现在尝试使用一个或三个隐藏层。

#### 2、小结

1. 如果要对 *N* 个类别的数据点进行分类，网络的最后一层应该是大小为 *N* 的 Dense 层。

2. 对于单标签、多分类问题，网络的最后一层应该使用 softmax 激活，这样可以输出在 *N*个输出类别上的概率分布。

3. 这种问题的损失函数几乎总是应该使用分类交叉熵。它将网络输出的概率分布与目标的真实分布之间的距离最小化。

4. 处理多分类问题的标签有两种方法。

   通过分类编码（也叫 one-hot 编码）对标签进行编码，然后使用 categorical_crossentropy 作为损失函数。

   将标签编码为整数，然后使用 sparse_categorical_crossentropy 损失函数。

5. 如果你需要将数据划分到许多类别中，应该避免使用太小的中间层，以免在网络中造成信息瓶颈。

### 三、深度学习用于计算机视觉

​	本章包括以下内容：

理解卷积神经网络（convnet） 

使用数据增强来降低过拟合

使用预训练的卷积神经网络进行特征提取

微调预训练的卷积神经网络

将卷积神经网络学到的内容及其如何做出分类决策可视化

#### （一）猫狗分类